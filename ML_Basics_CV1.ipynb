{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Basics_CV1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMh9RoJyBcQ8jEWvaaxwXjl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaNerpagar/TensorFlow_ML_basics/blob/main/ML_Basics_CV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WtMvdC8I1wAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d82b3cb1-830d-45cc-c67f-ebc39182f607"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) is a collection of grayscale 28x28 pixel clothing images. Each image is associated with a label as shown in this table‚Åâ\n",
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |\n",
        "\n",
        "This dataset is available directly in the [tf.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) API and you load it like this:"
      ],
      "metadata": {
        "id": "gKZ_TXF66Sr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Load dataset(Fashion MNIST) from set of datasets of keras"
      ],
      "metadata": {
        "id": "nn6dTZxd6vBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating object of class Fashion mnist dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist \n",
        "#fashion_mnist dataset from dataset of keras of tensorflow"
      ],
      "metadata": {
        "id": "SgIbP9aY6IBE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load_data returns two tuples with two lists each\n",
        "#divide datasets into training sets and test set which contains pair of\n",
        "#image and corresponding label\n",
        "(train_img,train_lab),(test_img,test_lab) = fmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFXXvK436j7Q",
        "outputId": "0b0df69f-19d4-4f41-e8f5-bb6708442db8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Import numpy and define image parameters"
      ],
      "metadata": {
        "id": "e_LlhIEv8Ft6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#choose number of image from dataset\n",
        "index = 25\n",
        "\n",
        "# Set number of characters per row when printing \n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "# Print the label and image\n",
        "print(f'LABEL: {train_lab[index]}')\n",
        "print(f'\\nIMAGE PIXEL ARRAY:\\n {train_img[index]}')\n",
        "\n",
        "#showing loaded image\n",
        "plt.imshow(train_img[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "7oxNHRE37bY_",
        "outputId": "ad46a30e-cca8-4233-ea6b-6ee347380d8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 3\n",
            "\n",
            "IMAGE PIXEL ARRAY:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0  51   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 139 214 218 220 164 206 243 233 205  93   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 130 253 225 226 233 229 232 230 219 227 249  63   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 203 237 221 222 221 222 219 220 224 218 233 191   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 232 237 224 225 224 224 222 221 225 218 224 253   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 232 223 225 222 221 219 216 219 212 223 255  30   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   5 255 230 224 221 223 218 219 217 221 214 229 255  89   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  32 255 228 221 220 223 221 221 218 217 221 232 255 113   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  78 255 227 218 220 221 226 225 219 215 232 168 255 148   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 115 255 237 221 221 218 228 227 219 216 241 107 255 152   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 144 255 218 223 220 215 223 222 215 216 240 119 255 154   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 167 255 102 224 223 215 219 220 213 213 234 131 255 165   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 170 255  34 221 229 215 217 217 214 216 238 102 254 175   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 172 255  27 235 225 215 214 215 215 213 246 104 253 181   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 173 255  18 249 217 215 215 215 216 210 241  95 247 183   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 172 255  19 252 214 216 215 214 215 211 245 106 244 176   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 164 254  27 253 212 217 216 214 215 214 243 110 243 145   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 169 255  42 253 211 215 218 218 215 215 233 149 255 141   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 103 131  49 253 212 216 222 219 217 214 249 128 122  78   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  58 254 218 217 225 218 219 212 253 110   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  64 237 219 220 229 217 222 217 235 129   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  54 239 221 222 231 215 225 217 237 125   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  50 241 220 224 233 212 227 217 241 120   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  41 242 222 226 236 213 228 220 243 113   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  33 242 224 228 239 216 230 221 245  97   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  13 237 224 226 235 208 226 218 246  65   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0 217 244 245 255 253 241 236 248  22   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 115 181 103  54 141 146 134 101   0   0   1   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f477f004cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize training and test images \n",
        "\n",
        "train_img = train_img / 255.0\n",
        "test_img = test_img / 255.0"
      ],
      "metadata": {
        "id": "uudQ1X5Y9ds2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Making model\n",
        "\n",
        "\n",
        "First Layer:  the first layer in your network should be the same shape as your data, we add the Flatten() layer at the begining, and when the arrays are loaded into the model later, they'll automatically be flattened for us.\n",
        "\n",
        "\n",
        "Last Layer: the number of neurons in the last layer should match the number of classes you are classifying for"
      ],
      "metadata": {
        "id": "vzs2ITbG-89I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using sequntial layers \n",
        "#flatten is used to flatten 28x28 image array into one layer\n",
        "#using 128 neurons in second layer with rectified linear unit activation\n",
        "#last layer will have 10 neurons and softmax activation\n",
        "model1 = tf.keras.Sequential([\n",
        "                              tf.keras.layers.Flatten(),\n",
        "                              tf.keras.layers.Dense(128,activation = tf.nn.relu),\n",
        "                              tf.keras.layers.Dense(10,activation = tf.nn.softmax)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "8CGMndvc-m04"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_more_layers = tf.keras.Sequential([\n",
        "                                          tf.keras.layers.Flatten(),\n",
        "                                          tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
        "                                          tf.keras.layers.Dense(128,activation = tf.nn.relu),\n",
        "                                          tf.keras.layers.Dense(10,activation= tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "-ngiAXOTJmi9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build model with compile \n",
        "#here optimizer used is Adam and loss function used is \n",
        "#sparse categorical crossentropy another input with \n",
        "#name metrics = ['accuracy'] is passed\n",
        "#train model with fit\n",
        "model1.compile(optimizer= tf.optimizers.Adam(),\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "model1.fit(train_img,train_lab,epochs = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNP-nZjiCHTt",
        "outputId": "528a01c7-4d29-4f2c-f7e0-628bc99dc9f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2814 - accuracy: 0.8963\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2666 - accuracy: 0.9016\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2555 - accuracy: 0.9050\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2479 - accuracy: 0.9061\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9112\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f477a777090>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_more_layers.compile(optimizer='Adam',\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "model_more_layers.fit(train_img,train_lab,epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Met5eT0SJkUq",
        "outputId": "2bf0965f-0621-4c3b-fef6-e7a25dd83594"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4879 - accuracy: 0.8260\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3656 - accuracy: 0.8659\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3287 - accuracy: 0.8786\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3076 - accuracy: 0.8858\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2900 - accuracy: 0.8919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f477a822850>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating model1\n",
        "model1.evaluate(test_img,test_lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AgZoWL2Ep-Q",
        "outputId": "e70fa3e5-28d0-4bbe-ba55-918610484db5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36200517416000366, 0.869700014591217]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_more_layers.evaluate(test_img,test_lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "232hJDxZFFEB",
        "outputId": "602d0c83-56ee-4ab0-9558-78e159a833c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38765788078308105, 0.862500011920929]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopping training midway \n",
        "\n",
        "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
      ],
      "metadata": {
        "id": "i1TzAqVWYm5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.95): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=30, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btHRMoR0TzUP",
        "outputId": "345e8b22-5f3f-4ed9-dfb1-c57123dad7b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4759 - accuracy: 0.8309\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3581 - accuracy: 0.8680\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3235 - accuracy: 0.8803\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2993 - accuracy: 0.8900\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2799 - accuracy: 0.8967\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2646 - accuracy: 0.9012\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2528 - accuracy: 0.9053\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2401 - accuracy: 0.9108\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2311 - accuracy: 0.9140\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2188 - accuracy: 0.9175\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2119 - accuracy: 0.9193\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2055 - accuracy: 0.9226\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1964 - accuracy: 0.9261\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1882 - accuracy: 0.9289\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1849 - accuracy: 0.9298\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1798 - accuracy: 0.9314\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1738 - accuracy: 0.9343\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1663 - accuracy: 0.9378\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1625 - accuracy: 0.9370\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1580 - accuracy: 0.9398\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1531 - accuracy: 0.9416\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1491 - accuracy: 0.9431\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1452 - accuracy: 0.9449\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1414 - accuracy: 0.9463\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1360 - accuracy: 0.9479\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1341 - accuracy: 0.9493\n",
            "Epoch 27/30\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9503\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9504\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f477a655d10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tgn76_1gY2Pp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}